data:
    resize: null
    scale: null
    clip_outliers: false
    to_tensor: true
    normalise: null

    condition:
        mode: null
        condition_path: null    
        resize: null
        scale: null
        clip_outliers: false
        to_tensor: true
        normalise: false

logging:
    tool: tensorboard

autoencoder:
    model:
        in_channels: 3
        out_channels: 3
        feature_channels: 64
        z_channels : 4
        embbeded_channels : 4
        channels_mult: [1, 2, 4]
        num_res_blocks: 2
        recon_loss: l2
        div_loss: kl
        perceptual_loss: null
        checkpoint: null

    params:
        div_weight: 0.001
        perceptual_weight: 1.
        recon_weight: 1.
        
    training:
        batch_size: 32
        n_epochs: 100 
        save_recon_freq: 100 
        ckpt_freq: 100
        ckpt_last_only: true
        num_workers: 32
        sampling_freq: 0

    validation:
        split: 0.1
        batch_size: 32
        freq: 10
        save_recon_freq: 100
        num_workers: 32

    sampling:
        batch_size: 32
        n_samples: 0
        num_workers: 32

    optim:
        weight_decay: 0.000
        bias_weight_decay: false
        optimiser: "Adam"
        lr: 0.00002
        beta1: 0.9
        amsgrad: false
        eps: 0.00000001
        grad_clip: null
        lr_scheduler:
            scheduler: null

diffusion:
    model:
        feature_channels: 128
        channels_mult: [1, 1, 2, 2]
        num_res_blocks: 2
        attention: [0, 1, 2, 3]
        num_transformer_layers: 1
        num_attn_heads: 8
        loss: l2
        checkpoint: null
        condition:
            in_channels: 1
            feature_channels: 98

    params:
        beta_schedule: linear
        beta_start: 0.0001
        beta_end: 0.02
        num_diffusion_timesteps: 100
        latent_scaling_factor: 1.
        sampler : ddpm

    training:
        batch_size: 32
        n_epochs: 100
        sampling_freq: 50
        sampling_temperature: 0.5
        sampling_skip_steps: 0
        ckpt_freq: 100
        ckpt_last_only: true
        num_workers: 32 

    validation:
        split: 0.1
        batch_size: 32
        freq: 10
        sampling_freq: 50
        num_workers: 4

    sampling:
        batch_size: 32
        temperature: 1.
        skip_steps: 0
        n_samples: 100
        num_workers: 32
        output: last_only

    optim:
        weight_decay: 0.000
        bias_weight_decay: false
        optimiser: "Adam"
        lr: 0.00002
        beta1: 0.9
        amsgrad: false
        eps: 0.00000001
        grad_clip: null

        lr_scheduler:
            scheduler: null